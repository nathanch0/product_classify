{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image sizes\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "# These model weights are downloaded from github repo for keras\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_path = 'Training_Data/'\n",
    "validation_data_path = 'Validation_Data/'\n",
    "\n",
    "# Epochs to train top model\n",
    "epochs = 50\n",
    "\n",
    "# Batch sizes\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_save_bottleneck_features():\n",
    "    \"\"\"\n",
    "    This function will build out our bottleneck features from our training data\n",
    "    using the weights that were established by VGG-16 (Transfer learning)\n",
    "    \"\"\"\n",
    "    # build VGG16 network. We do not want to include the final fully-connected layers\n",
    "    # and we load the Imagenet weights\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Make bottleneck features for training set\n",
    "    generator = data_generator.flow_from_directory(train_data_path,\n",
    "                                                   target_size = (img_width, img_height),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = None,\n",
    "                                                   shuffle = False)\n",
    "\n",
    "    # print(len(generator.filenames)) #This shows the number of files in train_data\n",
    "    # print(generator.class_indices) #This shows a dictionary of the titles of the sub-directories and its coorisponding number\n",
    "    # print(len(generator.class_indices)) #This shows the number of classes in total (63)\n",
    "\n",
    "    nb_train_samples = len(generator.filenames)\n",
    "    num_classes = len(generator.class_indices)\n",
    "\n",
    "    predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(generator, predict_size_train, verbose=1)\n",
    "\n",
    "    np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
    "\n",
    "    # Make bottleneck features for validation set\n",
    "    generator_val = data_generator.flow_from_directory(validation_data_path,\n",
    "                                                       target_size=(img_width,img_height),\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode=None,\n",
    "                                                       shuffle=False)\n",
    "\n",
    "    nb_validation_samples = len(generator_val.filenames)\n",
    "\n",
    "    predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "\n",
    "    bottleneck_features_validation = model.predict_generator(generator_val, predict_size_validation)\n",
    "\n",
    "    np.save('bottleneck_features_validation.npy', bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    \"\"\"\n",
    "    This function will load the saved bottleneck features that were established from applying transfer learning\n",
    "    onto the train and validation data. The function will use these features to train a fully connected network\n",
    "    with its output as our desired classes\n",
    "    \"\"\"\n",
    "    train_data = np.load('bottleneck_features_train.npy')\n",
    "\n",
    "    data_generator_top = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # Make top model generator for training set\n",
    "    generator_top_train = data_generator_top.flow_from_directory(train_data_path,\n",
    "                                                                 target_size=(img_width,img_height),\n",
    "                                                                 batch_size=batch_size,\n",
    "                                                                 class_mode='categorical',\n",
    "                                                                 shuffle=False)\n",
    "\n",
    "    nb_train_samples = len(generator_top_train.filenames)\n",
    "    num_classes = len(generator_top_train.class_indices)\n",
    "\n",
    "    # We save these to use in prediction step\n",
    "    np.save('class_indices.npy', generator_top_train.class_indices)\n",
    "\n",
    "    # Get the category labels for the training data\n",
    "    train_labels = generator_top_train.classes\n",
    "\n",
    "    train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "    # Make top model generator for validation set\n",
    "    validation_data = np.load('bottleneck_features_validation.npy')\n",
    "\n",
    "    generator_top_validation = data_generator_top.flow_from_directory(validation_data_path,\n",
    "                                                                 target_size=(img_width,img_height),\n",
    "                                                                 batch_size=batch_size,\n",
    "                                                                 class_mode=None,\n",
    "                                                                 shuffle=False)\n",
    "\n",
    "    nb_validation_samples = len(generator_top_validation.filenames)\n",
    "\n",
    "    # Get the category labels for the validation data\n",
    "    validation_labels = generator_top_validation.classes\n",
    "\n",
    "    validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "    # Lets make the model shall we?\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels, epochs=epochs,\n",
    "                                        batch_size=batch_size,\n",
    "                                        validation_data=(validation_data,validation_labels))\n",
    "\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "    (eval_loss, eval_accuracy) = model.evaluate(validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    print(\"Accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "    print(\"Loss: {}\".format(eval_loss))\n",
    "    \n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4774 images belonging to 63 classes.\n",
      "299/299 [==============================] - 535s 2s/step\n",
      "Found 1260 images belonging to 63 classes.\n"
     ]
    }
   ],
   "source": [
    "make_save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4774 images belonging to 63 classes.\n",
      "Found 1260 images belonging to 63 classes.\n",
      "Train on 4774 samples, validate on 1260 samples\n",
      "Epoch 1/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: 4.3467 - acc: 0.0582 - val_loss: 3.5451 - val_acc: 0.1865\n",
      "Epoch 2/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: 3.5900 - acc: 0.1573 - val_loss: 3.2874 - val_acc: 0.2405\n",
      "Epoch 3/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: 3.2119 - acc: 0.2258 - val_loss: 3.1500 - val_acc: 0.2651\n",
      "Epoch 4/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: 3.0279 - acc: 0.2664 - val_loss: 3.1494 - val_acc: 0.3071\n",
      "Epoch 5/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: 2.8377 - acc: 0.3002 - val_loss: 3.1788 - val_acc: 0.3143\n",
      "Epoch 6/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: 2.7177 - acc: 0.3477 - val_loss: 2.7849 - val_acc: 0.3746\n",
      "Epoch 7/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: 2.6223 - acc: 0.3674 - val_loss: 2.9299 - val_acc: 0.3571\n",
      "Epoch 8/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: 2.5317 - acc: 0.3825 - val_loss: 2.7946 - val_acc: 0.3913\n",
      "Epoch 9/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.3402 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 10/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 11/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 12/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 13/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 14/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 15/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 16/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 17/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 18/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 19/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 20/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 21/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 22/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 23/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 24/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 25/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 26/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 27/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 28/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 29/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 30/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 31/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 32/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 33/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 34/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 35/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 36/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 37/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 38/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 39/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 40/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 41/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 42/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 43/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 44/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 45/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 46/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 47/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 48/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 49/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "Epoch 50/50\n",
      "4774/4774 [==============================] - 7s 1ms/step - loss: nan - acc: 0.0121 - val_loss: nan - val_acc: 0.0159\n",
      "1260/1260 [==============================] - 0s 291us/step\n",
      "Accuracy: 1.59%\n",
      "Loss: nan\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
